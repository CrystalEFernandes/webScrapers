{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee24682",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13200\\18608384.py:18: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=self.driver_path, chrome_options=option)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13200\\18608384.py:18: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(executable_path=self.driver_path, chrome_options=option)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicked at coordinates (191, 363).\n",
      "Title of the LinkedIn person: UI/UX Frontend Intern at Svritz Technologies | Vice-Chairperson at Mozilla Campus Club CRCE | Student at Fr. Conceicao Rodrigues College of Engineering\n",
      "Experience not found.\n",
      "Education:\n",
      "Fr. Conceicao Rodrigues College of Engineering\n",
      "-\n",
      "2021 - 2025\n",
      "Activities:\n",
      "Certifications not found.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "class LinkedInBot:\n",
    "    def __init__(self, driver_path=r\"C:\\Users\\HP\\Downloads\\WEB SCRAPING\\chromedriver.exe\"):\n",
    "        self.driver_path = driver_path\n",
    "        self.user_agent = UserAgent().random\n",
    "        self.driver = self.create_driver()\n",
    "\n",
    "    def create_driver(self):\n",
    "        option = webdriver.ChromeOptions()\n",
    "        option.add_argument(f'user-agent={self.user_agent}')\n",
    "        option.add_argument('--disable-blink-features=AutomationControlled')\n",
    "        option.add_argument(\"--window-size=1920,1080\")\n",
    "        driver = webdriver.Chrome(executable_path=self.driver_path, chrome_options=option)\n",
    "        driver.maximize_window()\n",
    "        return driver\n",
    "\n",
    "    def open_url(self, url):\n",
    "        self.driver.get(url)\n",
    "        \n",
    "        try:\n",
    "            self.driver.find_element(By.TAG_NAME, 'body').click()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            time.sleep(3)\n",
    "            x = 191\n",
    "            y = 363\n",
    "\n",
    "            action = ActionChains(self.driver)\n",
    "            action.move_by_offset(x, y).click().perform()\n",
    "            print(\"Clicked at coordinates ({}, {}).\".format(x, y))\n",
    "        except Exception as e:\n",
    "            print(\"Failed to click at coordinates ({}, {}):\".format(x, y), e)\n",
    "\n",
    "    def scrape_data(self):\n",
    "        try:\n",
    "            title_element = self.driver.find_element(By.CLASS_NAME, 'top-card-layout__headline')\n",
    "            title = title_element.text\n",
    "            print(\"Title of the LinkedIn person:\", title)\n",
    "            return title\n",
    "        except Exception as e:\n",
    "            return None\n",
    "    \n",
    "    def scrape_experience(self):\n",
    "        try:\n",
    "            experience_list = self.driver.find_element(By.CLASS_NAME, 'experience__list')\n",
    "            experiences = experience_list.find_elements(By.TAG_NAME, 'li')\n",
    "            print(\"Experiences:\")\n",
    "            for experience in experiences:\n",
    "                print(experience.text)\n",
    "        except Exception as e:\n",
    "            print(\"Experience not found.\")\n",
    "    \n",
    "    def scrape_education(self):\n",
    "        try:\n",
    "            education_list = self.driver.find_element(By.CLASS_NAME, 'education__list')\n",
    "            educations = education_list.find_elements(By.TAG_NAME, 'li')\n",
    "            print(\"Education:\")\n",
    "            for education in educations:\n",
    "                print(education.text)\n",
    "        except Exception as e:\n",
    "            print(\"Education not found.\")\n",
    "    \n",
    "    def scrape_activities(self):\n",
    "        try:\n",
    "            activities_lists = self.driver.find_elements(By.CSS_SELECTOR, '[data-test-id=\"activities__list\"]')\n",
    "            unique_activities = set()\n",
    "            for activities_list in activities_lists:\n",
    "                activities = activities_list.find_elements(By.TAG_NAME, 'li')\n",
    "                for activity in activities:\n",
    "                    unique_activities.add(activity.text)\n",
    "            unique_activities_list = list(unique_activities)\n",
    "            cleaned_activities_list = self.clean_activities_list(unique_activities_list)\n",
    "            print(\"Activities:\")\n",
    "            for activity in cleaned_activities_list:\n",
    "                print(activity)\n",
    "                print('\\n')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Activities not found.\")\n",
    "    \n",
    "    def clean_activities_list(self, activities_list):\n",
    "        cleaned_activities = []\n",
    "        unique_activities = set()\n",
    "        for activity in activities_list:\n",
    "            activity_text = activity.split(\"Liked by\")[0].strip()\n",
    "            unique_activities.add(activity_text) \n",
    "\n",
    "        unique_activities_list = list(unique_activities)\n",
    "\n",
    "        for activity in unique_activities_list:\n",
    "            halfway_index = len(activity) // 2\n",
    "            first_half_activity = activity[:halfway_index]\n",
    "            cleaned_activities.append(first_half_activity)\n",
    "\n",
    "        return cleaned_activities\n",
    "\n",
    "    \n",
    "    def scrape_certifications(self):\n",
    "        try:\n",
    "            certifications_section = self.driver.find_element(By.CSS_SELECTOR, '[data-section=\"certifications\"]')\n",
    "            certifications = certifications_section.find_elements(By.TAG_NAME, 'li')\n",
    "\n",
    "            print(\"Certifications:\")\n",
    "            for certification in certifications:\n",
    "                cert_text = certification.text.replace(\"See credential\", \"\")\n",
    "                print(cert_text)\n",
    "        except Exception as e:\n",
    "            print(\"Certifications not found.\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "bot = LinkedInBot()\n",
    "bot.open_url('https://www.linkedin.com/in/crystal-fernandes-752347263/')\n",
    "linkedin_profile = bot.scrape_data() \n",
    "experiences_text = bot.scrape_experience()\n",
    "education_text = bot.scrape_education()\n",
    "activities_text = bot.scrape_activities()\n",
    "certifications_text = bot.scrape_certifications()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c15701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
